# Kubernetes

- Master Node (Manage plan, schedule, moitor)
  - ETCD Cluster
  - kube-apiserver
  - kube-controller-manager
  - kube-scheduler
- Worker Nodes (Host applications as containers)
  - kubelet
  - kube-proxy
  - Container run time engine(Docker, Containerd, Rkt)

- Control Plan
  - API Server(Kube-apiserver) - is the gateway to the clusters
  - Scheduler
  - Bunch of controllers
  - Persistance store (`etcd`) [`etcd` is stateful]
  - Kube-scheduler
    - Controller-manager
      - Node-Controller
      - Replication-Controller
- Worker (where the app runs)

- Kubernetes Primer
- Kubernetes API
- Kubernetes Objects
- Kubernetes Cluster

- Cluod-native apps are built from lots of small interactive services, form together to something useful app.
- These small components make them scalable.

- `pod` & `deploy` exist in the api group
- `pod`: Wrap one or more containers
- `deploy`: Scalability and application releases
- `ds`(DaemonSet): One Pod per node
- `sts`: Stateful app components

## Kubernetes Networking

- All Nodes of the clusters can talk to each other
- All Pods of the clusters can talk each other without NAT
- Every Pod gets its own IP address
- Node Network(Kubernetes doesn't implement Node Network)
  - 433 Port(HTTPS)
  - Pod Network
- Pod Network(Kubernetes provide the Pod network plugin interface)
  - CNI (Container Network Interface) plugin
  - Every Pod has an IP address
  - Each node gets allocated subset of addresses from Pod IP address
- *Service Network* - When a service is created, it gets a unique long lived IP. But this IP is neither on any Node Network nor on Pod Network. It is on actually 3rd Network, which is called `Service Network`. This `Service Network` doesn't have any interface. There is no routes either.
  - So, how the traffic gets into this network? Every Node on the network has the process called `kube-proxy`. Actually it runs on the cluster daemon sets. So one `kube-proxy` pod on every
  node. One of its main job is to write bunch of `IPVS/IPTABLES` rules on each node that says any requests that are listed in Service Network rewrite the headers and send them to the appropriate
  pod on the Pod Network.
  - `cbr0/custome bridge0` same as in `Docker0` in Docker Network. It s a bridge network.
  - Since Kubernetes v1.2 running `kube-proxy` in `IPTABLES` Mode is default. It doesn't sacle well and not really designed for load balancing.
  - From Kubernetes v1.11, there is new mode name `IPVS` Mode. It uses native IPVS of Linux Kernel. It is intended to be native Layer-4 Load Balancer. It supports more load balancing algorithms. In `IPVS` Mode, `Round Robin` is default. Under the hood, it can also do `least connection`, `source-hashing`, `destination-hashing`, `shortest expected delay` etc.
  - `kube-proxy` in IPVS mode creates dummy interfaces on the Service Network(called as `kube-ipbs0`).
  - `kube-proxy` in IPTABLES mode doesn't.

## Stable Network Abstraction

- Every Service gets a Name and an IP. Once the service is created, Kubernetes guarantees that the Name and the IP of the Service never changes in its entire life. That's how it.
solves the reliability issue.
- The Name and IP are registered with the clusters' built-in DNS(CoreDNS). Every Kubernetes server has native DNS service. And Pod in that clusters knows how to use it.
- How does the service know which Pods are live - When there is a service object with `Label` selector, Kubernetes also creates another object in the clusters named `End Point` object.
- `End Point` object contains list of Pod IPs and Pods.

## Service Types

- ClusterIP - is default type. Don't need to specify in the YAML spec.
  - Gets own IP
  - Only accessible from within cluster
- NodePort - top of ClusterIP
  - Gets cluster-wide port
  - Accessible from within and outside of cluster.
  - NodePort default range: 30000-32767. It can be changable by kub api server flag  `--service-node-port-range`
- LoadBalancer
  - Integrates with public cloud platform

### Kubernetes offers a very rich set of features for container orchestration. Some of its fully supported features are

- Automatic bin packing
  - Kubernetes automatically schedules containers based on resource needs and constraints, to maximize utilization without sacrificing availability.
- Self-healing
  - Kubernetes automatically replaces and reschedules containers from failed nodes. It kills and restarts containers unresponsive to health checks, based on existing rules/policy. It also prevents traffic from being routed to unresponsive containers.
- Horizontal scaling
  - With Kubernetes applications are scaled manually or automatically based on CPU or custom metrics utilization.
- Service discovery and Load balancing
  - Containers receive their own IP addresses from Kubernetes, white it assigns a single Domain Name System (DNS) name to a set of containers to aid in load-balancing requests across the containers of the set.
  - Annotate???
